{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e20e89",
   "metadata": {},
   "source": [
    "# SAM(세밀한 객체탐지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab369146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, FastSAM\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d21964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): SegmentationModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(8, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): C2PSA(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): PSABlock(\n",
       "            (attn): Attention(\n",
       "              (qkv): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (proj): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (pe): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (ffn): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (12): Concat()\n",
       "      (13): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (15): Concat()\n",
       "      (16): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (18): Concat()\n",
       "      (19): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (21): Concat()\n",
       "      (22): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): Segment(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (proto): Proto(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (upsample): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv4): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('yolo11n-seg.pt') # coco dataset 기준 분류\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f468026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\walker\\code\\deep-learning-models\\models\\sam\\..\\..\\data\\image\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 71.8ms\n",
      "Speed: 1.7ms preprocess, 71.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\walker\\code\\deep-learning-models\\runs\\segment\\predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: ultralytics.engine.results.Masks object\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "obb: None\n",
       "orig_img: array([[[119, 146, 172],\n",
       "        [121, 148, 174],\n",
       "        [122, 152, 177],\n",
       "        ...,\n",
       "        [161, 171, 188],\n",
       "        [160, 170, 187],\n",
       "        [160, 170, 187]],\n",
       "\n",
       "       [[120, 147, 173],\n",
       "        [122, 149, 175],\n",
       "        [123, 153, 178],\n",
       "        ...,\n",
       "        [161, 171, 188],\n",
       "        [160, 170, 187],\n",
       "        [160, 170, 187]],\n",
       "\n",
       "       [[123, 150, 176],\n",
       "        [124, 151, 177],\n",
       "        [125, 155, 180],\n",
       "        ...,\n",
       "        [161, 171, 188],\n",
       "        [160, 170, 187],\n",
       "        [160, 170, 187]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[183, 182, 186],\n",
       "        [179, 178, 182],\n",
       "        [180, 179, 183],\n",
       "        ...,\n",
       "        [121, 111, 117],\n",
       "        [113, 103, 109],\n",
       "        [115, 105, 111]],\n",
       "\n",
       "       [[165, 164, 168],\n",
       "        [173, 172, 176],\n",
       "        [187, 186, 190],\n",
       "        ...,\n",
       "        [102,  92,  98],\n",
       "        [101,  91,  97],\n",
       "        [103,  93,  99]],\n",
       "\n",
       "       [[123, 122, 126],\n",
       "        [145, 144, 148],\n",
       "        [176, 175, 179],\n",
       "        ...,\n",
       "        [ 95,  85,  91],\n",
       "        [ 96,  86,  92],\n",
       "        [ 98,  88,  94]]], shape=(1080, 810, 3), dtype=uint8)\n",
       "orig_shape: (1080, 810)\n",
       "path: 'c:\\\\walker\\\\code\\\\deep-learning-models\\\\models\\\\sam\\\\..\\\\..\\\\data\\\\image\\\\bus.jpg'\n",
       "probs: None\n",
       "save_dir: 'C:\\\\walker\\\\code\\\\deep-learning-models\\\\runs\\\\segment\\\\predict'\n",
       "speed: {'preprocess': 1.6781999729573727, 'inference': 71.82350009679794, 'postprocess': 4.34590014629066}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model('../../data/image/bus.jpg', save=True)\n",
    "result = results[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c32a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([ 5.,  0.,  0.,  0., 11.,  0.])\n",
      "conf: tensor([0.8985, 0.8849, 0.8628, 0.8223, 0.4611, 0.4428])\n",
      "data: tensor([[1.9683e+01, 2.3003e+02, 8.0179e+02, 7.4414e+02, 8.9853e-01, 5.0000e+00],\n",
      "        [6.7014e+02, 3.9057e+02, 8.0955e+02, 8.7529e+02, 8.8493e-01, 0.0000e+00],\n",
      "        [4.9487e+01, 3.9813e+02, 2.4076e+02, 9.0509e+02, 8.6281e-01, 0.0000e+00],\n",
      "        [2.2265e+02, 4.0454e+02, 3.4606e+02, 8.5989e+02, 8.2234e-01, 0.0000e+00],\n",
      "        [1.1447e-01, 2.5458e+02, 3.1959e+01, 3.2565e+02, 4.6115e-01, 1.1000e+01],\n",
      "        [0.0000e+00, 5.5533e+02, 7.4818e+01, 8.7502e+02, 4.4278e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 810)\n",
      "shape: torch.Size([6, 6])\n",
      "xywh: tensor([[410.7375, 487.0835, 782.1091, 514.1113],\n",
      "        [739.8477, 632.9328, 139.4077, 484.7191],\n",
      "        [145.1215, 651.6073, 191.2684, 506.9590],\n",
      "        [284.3539, 632.2175, 123.4095, 455.3473],\n",
      "        [ 16.0369, 290.1147,  31.8448,  71.0691],\n",
      "        [ 37.4089, 715.1753,  74.8179, 319.6833]])\n",
      "xywhn: tensor([[0.5071, 0.4510, 0.9656, 0.4760],\n",
      "        [0.9134, 0.5860, 0.1721, 0.4488],\n",
      "        [0.1792, 0.6033, 0.2361, 0.4694],\n",
      "        [0.3511, 0.5854, 0.1524, 0.4216],\n",
      "        [0.0198, 0.2686, 0.0393, 0.0658],\n",
      "        [0.0462, 0.6622, 0.0924, 0.2960]])\n",
      "xyxy: tensor([[1.9683e+01, 2.3003e+02, 8.0179e+02, 7.4414e+02],\n",
      "        [6.7014e+02, 3.9057e+02, 8.0955e+02, 8.7529e+02],\n",
      "        [4.9487e+01, 3.9813e+02, 2.4076e+02, 9.0509e+02],\n",
      "        [2.2265e+02, 4.0454e+02, 3.4606e+02, 8.5989e+02],\n",
      "        [1.1447e-01, 2.5458e+02, 3.1959e+01, 3.2565e+02],\n",
      "        [0.0000e+00, 5.5533e+02, 7.4818e+01, 8.7502e+02]])\n",
      "xyxyn: tensor([[2.4300e-02, 2.1299e-01, 9.8987e-01, 6.8902e-01],\n",
      "        [8.2734e-01, 3.6164e-01, 9.9945e-01, 8.1046e-01],\n",
      "        [6.1095e-02, 3.6864e-01, 2.9723e-01, 8.3804e-01],\n",
      "        [2.7488e-01, 3.7458e-01, 4.2723e-01, 7.9620e-01],\n",
      "        [1.4133e-04, 2.3572e-01, 3.9456e-02, 3.0153e-01],\n",
      "        [0.0000e+00, 5.1420e-01, 9.2368e-02, 8.1020e-01]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tensor([ 5.,  0.,  0.,  0., 11.,  0.])\n",
      "tensor([0.8985, 0.8849, 0.8628, 0.8223, 0.4611, 0.4428])\n",
      "tensor([[1.9683e+01, 2.3003e+02, 8.0179e+02, 7.4414e+02, 8.9853e-01, 5.0000e+00],\n",
      "        [6.7014e+02, 3.9057e+02, 8.0955e+02, 8.7529e+02, 8.8493e-01, 0.0000e+00],\n",
      "        [4.9487e+01, 3.9813e+02, 2.4076e+02, 9.0509e+02, 8.6281e-01, 0.0000e+00],\n",
      "        [2.2265e+02, 4.0454e+02, 3.4606e+02, 8.5989e+02, 8.2234e-01, 0.0000e+00],\n",
      "        [1.1447e-01, 2.5458e+02, 3.1959e+01, 3.2565e+02, 4.6115e-01, 1.1000e+01],\n",
      "        [0.0000e+00, 5.5533e+02, 7.4818e+01, 8.7502e+02, 4.4278e-01, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "boxes = result.boxes\n",
    "print(boxes)\n",
    "print('-' * 100)\n",
    "print(boxes.cls)\n",
    "print(boxes.conf)\n",
    "print(boxes.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb34d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = result.names\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd21488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(results[0].masks.data[5])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d1f0418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Masks object with attributes:\n",
       "\n",
       "data: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
       "orig_shape: (1080, 810)\n",
       "shape: torch.Size([6, 640, 480])\n",
       "xy: [array([[     185.62,      232.88],\n",
       "       [     185.62,      237.94],\n",
       "       [     183.94,      239.62],\n",
       "       ...,\n",
       "       [     410.06,      239.62],\n",
       "       [     408.38,      237.94],\n",
       "       [     408.38,      232.88]], shape=(669, 2), dtype=float32), array([[     804.94,      396.56],\n",
       "       [     803.25,      398.25],\n",
       "       [     801.56,      398.25],\n",
       "       [     799.88,      399.94],\n",
       "       [     798.19,      399.94],\n",
       "       [      796.5,      401.62],\n",
       "       [      796.5,      403.31],\n",
       "       [     791.44,      408.38],\n",
       "       [     791.44,      411.75],\n",
       "       [     789.75,      413.44],\n",
       "       [     789.75,       418.5],\n",
       "       [     788.06,      420.19],\n",
       "       [     788.06,      447.19],\n",
       "       [     789.75,      448.88],\n",
       "       [     789.75,      453.94],\n",
       "       [     791.44,      455.62],\n",
       "       [     791.44,      469.12],\n",
       "       [     789.75,      470.81],\n",
       "       [     789.75,      474.19],\n",
       "       [     788.06,      475.88],\n",
       "       [     788.06,      479.25],\n",
       "       [     786.38,      480.94],\n",
       "       [     786.38,      482.62],\n",
       "       [        783,         486],\n",
       "       [        783,      487.69],\n",
       "       [     781.31,      489.38],\n",
       "       [     781.31,      491.06],\n",
       "       [     779.62,      492.75],\n",
       "       [     779.62,      494.44],\n",
       "       [     776.25,      497.81],\n",
       "       [     776.25,       499.5],\n",
       "       [     774.56,      501.19],\n",
       "       [     774.56,      506.25],\n",
       "       [     772.88,      507.94],\n",
       "       [     772.88,      518.06],\n",
       "       [     771.19,      519.75],\n",
       "       [     771.19,      536.62],\n",
       "       [      769.5,      538.31],\n",
       "       [      769.5,      543.38],\n",
       "       [     762.75,      550.12],\n",
       "       [     761.06,      550.12],\n",
       "       [     759.38,      551.81],\n",
       "       [     757.69,      551.81],\n",
       "       [        756,      550.12],\n",
       "       [     740.81,      550.12],\n",
       "       [     735.75,      555.19],\n",
       "       [     740.81,      560.25],\n",
       "       [      742.5,      560.25],\n",
       "       [     744.19,      561.94],\n",
       "       [     744.19,      563.62],\n",
       "       [     745.88,      565.31],\n",
       "       [     745.88,      570.38],\n",
       "       [     747.56,      572.06],\n",
       "       [     747.56,      573.75],\n",
       "       [     749.25,      575.44],\n",
       "       [     749.25,      577.12],\n",
       "       [     750.94,      578.81],\n",
       "       [     750.94,       580.5],\n",
       "       [     762.75,      592.31],\n",
       "       [     762.75,      595.69],\n",
       "       [     764.44,      597.38],\n",
       "       [     764.44,      605.81],\n",
       "       [     762.75,       607.5],\n",
       "       [     762.75,      617.62],\n",
       "       [     761.06,      619.31],\n",
       "       [     761.06,      624.38],\n",
       "       [     759.38,      626.06],\n",
       "       [     759.38,      629.44],\n",
       "       [     757.69,      631.12],\n",
       "       [     757.69,      636.19],\n",
       "       [        756,      637.88],\n",
       "       [        756,      641.25],\n",
       "       [     754.31,      642.94],\n",
       "       [     754.31,      646.31],\n",
       "       [     752.62,         648],\n",
       "       [     752.62,      653.06],\n",
       "       [     750.94,      654.75],\n",
       "       [     750.94,      664.88],\n",
       "       [     749.25,      666.56],\n",
       "       [     749.25,      671.62],\n",
       "       [     747.56,      673.31],\n",
       "       [     747.56,      681.75],\n",
       "       [     749.25,      683.44],\n",
       "       [     749.25,      685.12],\n",
       "       [     752.62,       688.5],\n",
       "       [     752.62,      700.31],\n",
       "       [     750.94,         702],\n",
       "       [     750.94,      705.38],\n",
       "       [     749.25,      707.06],\n",
       "       [     749.25,      708.75],\n",
       "       [     747.56,      710.44],\n",
       "       [     747.56,      713.81],\n",
       "       [     745.88,       715.5],\n",
       "       [     745.88,      718.88],\n",
       "       [     744.19,      720.56],\n",
       "       [     744.19,      722.25],\n",
       "       [      742.5,      723.94],\n",
       "       [      742.5,      727.31],\n",
       "       [     740.81,         729],\n",
       "       [     740.81,      734.06],\n",
       "       [     739.12,      735.75],\n",
       "       [     739.12,      744.19],\n",
       "       [     737.44,      745.88],\n",
       "       [     737.44,      750.94],\n",
       "       [     735.75,      752.62],\n",
       "       [     735.75,         756],\n",
       "       [     734.06,      757.69],\n",
       "       [     734.06,      762.75],\n",
       "       [     732.38,      764.44],\n",
       "       [     732.38,      766.12],\n",
       "       [     730.69,      767.81],\n",
       "       [     730.69,      771.19],\n",
       "       [        729,      772.88],\n",
       "       [        729,      774.56],\n",
       "       [     727.31,      776.25],\n",
       "       [     727.31,      779.62],\n",
       "       [     725.62,      781.31],\n",
       "       [     725.62,      784.69],\n",
       "       [     723.94,      786.38],\n",
       "       [     723.94,      788.06],\n",
       "       [     722.25,      789.75],\n",
       "       [     722.25,      791.44],\n",
       "       [     720.56,      793.12],\n",
       "       [     720.56,      798.19],\n",
       "       [     718.88,      799.88],\n",
       "       [     718.88,      801.56],\n",
       "       [      715.5,      804.94],\n",
       "       [      715.5,      806.62],\n",
       "       [     713.81,      808.31],\n",
       "       [     713.81,      811.69],\n",
       "       [     712.12,      813.38],\n",
       "       [     712.12,      815.06],\n",
       "       [     703.69,       823.5],\n",
       "       [     700.31,       823.5],\n",
       "       [     698.62,      825.19],\n",
       "       [     690.19,      825.19],\n",
       "       [      688.5,       823.5],\n",
       "       [     671.62,       823.5],\n",
       "       [     671.62,      845.44],\n",
       "       [     678.38,      845.44],\n",
       "       [     683.44,       850.5],\n",
       "       [     685.12,       850.5],\n",
       "       [      688.5,      853.88],\n",
       "       [     690.19,      853.88],\n",
       "       [     691.88,      855.56],\n",
       "       [     693.56,      855.56],\n",
       "       [     695.25,      857.25],\n",
       "       [     696.94,      857.25],\n",
       "       [     698.62,      858.94],\n",
       "       [     700.31,      858.94],\n",
       "       [        702,      860.62],\n",
       "       [     703.69,      860.62],\n",
       "       [     707.06,         864],\n",
       "       [     708.75,         864],\n",
       "       [     710.44,      865.69],\n",
       "       [     712.12,      865.69],\n",
       "       [      715.5,      869.06],\n",
       "       [     717.19,      869.06],\n",
       "       [     720.56,      872.44],\n",
       "       [     720.56,      879.19],\n",
       "       [     735.75,      879.19],\n",
       "       [     735.75,      874.12],\n",
       "       [     737.44,      872.44],\n",
       "       [     737.44,      870.75],\n",
       "       [     739.12,      869.06],\n",
       "       [     739.12,      867.38],\n",
       "       [     740.81,      865.69],\n",
       "       [     740.81,      860.62],\n",
       "       [      742.5,      858.94],\n",
       "       [      742.5,      848.81],\n",
       "       [     744.19,      847.12],\n",
       "       [     744.19,      843.75],\n",
       "       [     745.88,      842.06],\n",
       "       [     745.88,      838.69],\n",
       "       [     747.56,         837],\n",
       "       [     747.56,      833.62],\n",
       "       [     749.25,      831.94],\n",
       "       [     749.25,      826.88],\n",
       "       [     754.31,      821.81],\n",
       "       [     754.31,      820.12],\n",
       "       [        756,      818.44],\n",
       "       [        756,      815.06],\n",
       "       [     759.38,      811.69],\n",
       "       [     759.38,         810],\n",
       "       [     761.06,      808.31],\n",
       "       [     761.06,      804.94],\n",
       "       [     762.75,      803.25],\n",
       "       [     762.75,      799.88],\n",
       "       [     766.12,       796.5],\n",
       "       [     766.12,      794.81],\n",
       "       [     767.81,      793.12],\n",
       "       [     767.81,      791.44],\n",
       "       [      769.5,      789.75],\n",
       "       [      769.5,      788.06],\n",
       "       [     771.19,      786.38],\n",
       "       [     771.19,         783],\n",
       "       [     772.88,      781.31],\n",
       "       [     772.88,      779.62],\n",
       "       [     774.56,      777.94],\n",
       "       [     774.56,      774.56],\n",
       "       [     776.25,      772.88],\n",
       "       [     776.25,       769.5],\n",
       "       [     777.94,      767.81],\n",
       "       [     777.94,      764.44],\n",
       "       [     779.62,      762.75],\n",
       "       [     779.62,      761.06],\n",
       "       [     781.31,      759.38],\n",
       "       [     781.31,      757.69],\n",
       "       [        783,         756],\n",
       "       [        783,      752.62],\n",
       "       [     784.69,      750.94],\n",
       "       [     784.69,      749.25],\n",
       "       [     786.38,      747.56],\n",
       "       [     786.38,      745.88],\n",
       "       [     788.06,      744.19],\n",
       "       [     788.06,       742.5],\n",
       "       [     789.75,      740.81],\n",
       "       [     789.75,      739.12],\n",
       "       [     791.44,      737.44],\n",
       "       [     791.44,      735.75],\n",
       "       [     793.12,      734.06],\n",
       "       [     793.12,      732.38],\n",
       "       [      796.5,         729],\n",
       "       [      796.5,      727.31],\n",
       "       [     798.19,      725.62],\n",
       "       [     798.19,      723.94],\n",
       "       [     801.56,      720.56],\n",
       "       [     801.56,      718.88],\n",
       "       [     803.25,      717.19],\n",
       "       [     803.25,       715.5],\n",
       "       [     806.62,      712.12],\n",
       "       [     808.31,      712.12],\n",
       "       [     808.31,      396.56]], dtype=float32), array([[     101.25,      394.88],\n",
       "       [     101.25,      401.62],\n",
       "       [     99.562,      403.31],\n",
       "       [     99.562,      406.69],\n",
       "       [     97.875,      408.38],\n",
       "       [     97.875,      413.44],\n",
       "       [     96.188,      415.12],\n",
       "       [     96.188,      426.94],\n",
       "       [       94.5,      428.62],\n",
       "       [       94.5,      453.94],\n",
       "       [     92.812,      455.62],\n",
       "       [     92.812,      462.38],\n",
       "       [     91.125,      464.06],\n",
       "       [     91.125,      465.75],\n",
       "       [     79.312,      477.56],\n",
       "       [     77.625,      477.56],\n",
       "       [     69.188,         486],\n",
       "       [     69.188,      487.69],\n",
       "       [       67.5,      489.38],\n",
       "       [       67.5,      491.06],\n",
       "       [     64.125,      494.44],\n",
       "       [     64.125,      496.12],\n",
       "       [     62.438,      497.81],\n",
       "       [     62.438,      502.88],\n",
       "       [      60.75,      504.56],\n",
       "       [      60.75,      521.44],\n",
       "       [     62.438,      523.12],\n",
       "       [     62.438,      543.38],\n",
       "       [      60.75,      545.06],\n",
       "       [      60.75,      550.12],\n",
       "       [     59.062,      551.81],\n",
       "       [     59.062,      561.94],\n",
       "       [      60.75,      563.62],\n",
       "       [      60.75,         567],\n",
       "       [     62.438,      568.69],\n",
       "       [     62.438,      575.44],\n",
       "       [     64.125,      577.12],\n",
       "       [     64.125,      590.62],\n",
       "       [     62.438,      592.31],\n",
       "       [     62.438,         621],\n",
       "       [      60.75,      622.69],\n",
       "       [      60.75,      641.25],\n",
       "       [     59.062,      642.94],\n",
       "       [     59.062,      681.75],\n",
       "       [      60.75,      683.44],\n",
       "       [      60.75,      691.88],\n",
       "       [     62.438,      693.56],\n",
       "       [     62.438,      695.25],\n",
       "       [     64.125,      696.94],\n",
       "       [     64.125,      698.62],\n",
       "       [       67.5,         702],\n",
       "       [       67.5,      703.69],\n",
       "       [     69.188,      705.38],\n",
       "       [     69.188,      707.06],\n",
       "       [     70.875,      708.75],\n",
       "       [     70.875,      750.94],\n",
       "       [     72.562,      752.62],\n",
       "       [     72.562,      762.75],\n",
       "       [      74.25,      764.44],\n",
       "       [      74.25,      772.88],\n",
       "       [     75.938,      774.56],\n",
       "       [     75.938,      786.38],\n",
       "       [      74.25,      788.06],\n",
       "       [      74.25,      791.44],\n",
       "       [     72.562,      793.12],\n",
       "       [     72.562,       796.5],\n",
       "       [     70.875,      798.19],\n",
       "       [     70.875,      799.88],\n",
       "       [     62.438,      808.31],\n",
       "       [     62.438,         810],\n",
       "       [     59.062,      813.38],\n",
       "       [     59.062,      821.81],\n",
       "       [     57.375,       823.5],\n",
       "       [     57.375,      831.94],\n",
       "       [     55.688,      833.62],\n",
       "       [     50.625,      833.62],\n",
       "       [     50.625,         891],\n",
       "       [     59.062,         891],\n",
       "       [     62.438,      894.38],\n",
       "       [     64.125,      894.38],\n",
       "       [     65.812,      896.06],\n",
       "       [       67.5,      896.06],\n",
       "       [     69.188,      897.75],\n",
       "       [     70.875,      897.75],\n",
       "       [     72.562,      899.44],\n",
       "       [     75.938,      899.44],\n",
       "       [     77.625,      901.12],\n",
       "       [       94.5,      901.12],\n",
       "       [     96.188,      899.44],\n",
       "       [     97.875,      899.44],\n",
       "       [     101.25,      896.06],\n",
       "       [     101.25,      894.38],\n",
       "       [     102.94,      892.69],\n",
       "       [     102.94,      885.94],\n",
       "       [     101.25,      884.25],\n",
       "       [     101.25,      882.56],\n",
       "       [     99.562,      880.88],\n",
       "       [     99.562,      879.19],\n",
       "       [     97.875,       877.5],\n",
       "       [     97.875,      875.81],\n",
       "       [       94.5,      872.44],\n",
       "       [       94.5,      870.75],\n",
       "       [     92.812,      869.06],\n",
       "       [     92.812,      867.38],\n",
       "       [     91.125,      865.69],\n",
       "       [     91.125,         864],\n",
       "       [      87.75,      860.62],\n",
       "       [      87.75,      838.69],\n",
       "       [     89.438,         837],\n",
       "       [     89.438,      833.62],\n",
       "       [     91.125,      831.94],\n",
       "       [     91.125,      821.81],\n",
       "       [     92.812,      820.12],\n",
       "       [     92.812,      806.62],\n",
       "       [       94.5,      804.94],\n",
       "       [       94.5,       796.5],\n",
       "       [     96.188,      794.81],\n",
       "       [     96.188,      791.44],\n",
       "       [     97.875,      789.75],\n",
       "       [     97.875,      786.38],\n",
       "       [     99.562,      784.69],\n",
       "       [     99.562,      781.31],\n",
       "       [     101.25,      779.62],\n",
       "       [     101.25,      776.25],\n",
       "       [     102.94,      774.56],\n",
       "       [     102.94,      772.88],\n",
       "       [     104.62,      771.19],\n",
       "       [     104.62,       769.5],\n",
       "       [     106.31,      767.81],\n",
       "       [     106.31,      766.12],\n",
       "       [        108,      764.44],\n",
       "       [        108,      757.69],\n",
       "       [     109.69,         756],\n",
       "       [     109.69,      744.19],\n",
       "       [     111.38,       742.5],\n",
       "       [     111.38,      735.75],\n",
       "       [     113.06,      734.06],\n",
       "       [     113.06,      727.31],\n",
       "       [     114.75,      725.62],\n",
       "       [     114.75,      722.25],\n",
       "       [     119.81,      717.19],\n",
       "       [      121.5,      717.19],\n",
       "       [     123.19,       715.5],\n",
       "       [     124.88,       715.5],\n",
       "       [     131.62,      722.25],\n",
       "       [     131.62,      725.62],\n",
       "       [     133.31,      727.31],\n",
       "       [     133.31,       742.5],\n",
       "       [        135,      744.19],\n",
       "       [        135,      745.88],\n",
       "       [     140.06,      750.94],\n",
       "       [     140.06,      752.62],\n",
       "       [     141.75,      754.31],\n",
       "       [     141.75,         756],\n",
       "       [     145.12,      759.38],\n",
       "       [     145.12,      761.06],\n",
       "       [     146.81,      762.75],\n",
       "       [     146.81,      766.12],\n",
       "       [      148.5,      767.81],\n",
       "       [      148.5,      771.19],\n",
       "       [     150.19,      772.88],\n",
       "       [     150.19,      776.25],\n",
       "       [     151.88,      777.94],\n",
       "       [     151.88,      784.69],\n",
       "       [     153.56,      786.38],\n",
       "       [     153.56,      794.81],\n",
       "       [     155.25,       796.5],\n",
       "       [     155.25,      799.88],\n",
       "       [     156.94,      801.56],\n",
       "       [     156.94,      806.62],\n",
       "       [     158.62,      808.31],\n",
       "       [     158.62,      813.38],\n",
       "       [     160.31,      815.06],\n",
       "       [     160.31,       823.5],\n",
       "       [        162,      825.19],\n",
       "       [        162,      828.56],\n",
       "       [     163.69,      830.25],\n",
       "       [     163.69,      831.94],\n",
       "       [     165.38,      833.62],\n",
       "       [     165.38,      838.69],\n",
       "       [     167.06,      840.38],\n",
       "       [     167.06,      847.12],\n",
       "       [     168.75,      848.81],\n",
       "       [     168.75,      852.19],\n",
       "       [     170.44,      853.88],\n",
       "       [     170.44,      855.56],\n",
       "       [     172.12,      857.25],\n",
       "       [     172.12,      860.62],\n",
       "       [     173.81,      862.31],\n",
       "       [     173.81,      882.56],\n",
       "       [      175.5,      884.25],\n",
       "       [      175.5,         891],\n",
       "       [     177.19,      892.69],\n",
       "       [     177.19,      894.38],\n",
       "       [     178.88,      896.06],\n",
       "       [     205.88,      896.06],\n",
       "       [     207.56,      894.38],\n",
       "       [     212.62,      894.38],\n",
       "       [     214.31,      892.69],\n",
       "       [     219.38,      892.69],\n",
       "       [     221.06,         891],\n",
       "       [     226.12,         891],\n",
       "       [     227.81,      889.31],\n",
       "       [      229.5,      889.31],\n",
       "       [     231.19,      887.62],\n",
       "       [     232.88,      887.62],\n",
       "       [     234.56,      885.94],\n",
       "       [     234.56,      882.56],\n",
       "       [     236.25,      880.88],\n",
       "       [     236.25,      879.19],\n",
       "       [     232.88,      875.81],\n",
       "       [     232.88,      874.12],\n",
       "       [     231.19,      872.44],\n",
       "       [     227.81,      872.44],\n",
       "       [     207.56,      852.19],\n",
       "       [     207.56,       850.5],\n",
       "       [     205.88,      848.81],\n",
       "       [     205.88,      847.12],\n",
       "       [     204.19,      845.44],\n",
       "       [     204.19,      840.38],\n",
       "       [      202.5,      838.69],\n",
       "       [      202.5,      833.62],\n",
       "       [     200.81,      831.94],\n",
       "       [     200.81,      825.19],\n",
       "       [     199.12,       823.5],\n",
       "       [     199.12,      820.12],\n",
       "       [     197.44,      818.44],\n",
       "       [     197.44,         810],\n",
       "       [     195.75,      808.31],\n",
       "       [     195.75,      794.81],\n",
       "       [     194.06,      793.12],\n",
       "       [     194.06,      784.69],\n",
       "       [     192.38,         783],\n",
       "       [     192.38,      779.62],\n",
       "       [     190.69,      777.94],\n",
       "       [     190.69,       769.5],\n",
       "       [        189,      767.81],\n",
       "       [        189,      754.31],\n",
       "       [     187.31,      752.62],\n",
       "       [     187.31,      737.44],\n",
       "       [     185.62,      735.75],\n",
       "       [     185.62,         729],\n",
       "       [     183.94,      727.31],\n",
       "       [     183.94,      720.56],\n",
       "       [     182.25,      718.88],\n",
       "       [     182.25,      696.94],\n",
       "       [     183.94,      695.25],\n",
       "       [     183.94,      693.56],\n",
       "       [     192.38,      685.12],\n",
       "       [     192.38,      666.56],\n",
       "       [     190.69,      664.88],\n",
       "       [     190.69,      656.44],\n",
       "       [        189,      654.75],\n",
       "       [        189,      649.69],\n",
       "       [     187.31,         648],\n",
       "       [     187.31,      642.94],\n",
       "       [     185.62,      641.25],\n",
       "       [     185.62,       634.5],\n",
       "       [     183.94,      632.81],\n",
       "       [     183.94,      626.06],\n",
       "       [     182.25,      624.38],\n",
       "       [     182.25,      615.94],\n",
       "       [     180.56,      614.25],\n",
       "       [     180.56,      604.12],\n",
       "       [     183.94,      600.75],\n",
       "       [     183.94,      599.06],\n",
       "       [     199.12,      583.88],\n",
       "       [     199.12,      582.19],\n",
       "       [     200.81,       580.5],\n",
       "       [     200.81,      573.75],\n",
       "       [      202.5,      572.06],\n",
       "       [      202.5,      561.94],\n",
       "       [     200.81,      560.25],\n",
       "       [     200.81,      555.19],\n",
       "       [     199.12,       553.5],\n",
       "       [     199.12,      551.81],\n",
       "       [     197.44,      550.12],\n",
       "       [     197.44,      548.44],\n",
       "       [     194.06,      545.06],\n",
       "       [     194.06,      543.38],\n",
       "       [     190.69,         540],\n",
       "       [     190.69,      538.31],\n",
       "       [        189,      536.62],\n",
       "       [        189,      534.94],\n",
       "       [     187.31,      533.25],\n",
       "       [     187.31,      531.56],\n",
       "       [     185.62,      529.88],\n",
       "       [     185.62,      524.81],\n",
       "       [     183.94,      523.12],\n",
       "       [     183.94,      516.38],\n",
       "       [     182.25,      514.69],\n",
       "       [     182.25,      506.25],\n",
       "       [     180.56,      504.56],\n",
       "       [     180.56,      501.19],\n",
       "       [     178.88,       499.5],\n",
       "       [     178.88,      497.81],\n",
       "       [      175.5,      494.44],\n",
       "       [      175.5,      492.75],\n",
       "       [     172.12,      489.38],\n",
       "       [     172.12,      487.69],\n",
       "       [     168.75,      484.31],\n",
       "       [     168.75,      482.62],\n",
       "       [        162,      475.88],\n",
       "       [        162,      474.19],\n",
       "       [     153.56,      465.75],\n",
       "       [     153.56,      464.06],\n",
       "       [     151.88,      462.38],\n",
       "       [     151.88,      453.94],\n",
       "       [     153.56,      452.25],\n",
       "       [     153.56,       445.5],\n",
       "       [     155.25,      443.81],\n",
       "       [     155.25,         405],\n",
       "       [     153.56,      403.31],\n",
       "       [     153.56,      401.62],\n",
       "       [     151.88,      399.94],\n",
       "       [     151.88,      394.88]], dtype=float32), array([[     264.94,      401.62],\n",
       "       [     264.94,      408.38],\n",
       "       [     263.25,      410.06],\n",
       "       [     263.25,      411.75],\n",
       "       [     261.56,      413.44],\n",
       "       [     261.56,       418.5],\n",
       "       [     259.88,      420.19],\n",
       "       [     259.88,      425.25],\n",
       "       [     258.19,      426.94],\n",
       "       [     258.19,      440.44],\n",
       "       [     259.88,      442.12],\n",
       "       [     259.88,      448.88],\n",
       "       [     261.56,      450.56],\n",
       "       [     261.56,         459],\n",
       "       [     263.25,      460.69],\n",
       "       [     261.56,      462.38],\n",
       "       [     261.56,      464.06],\n",
       "       [     259.88,      465.75],\n",
       "       [     259.88,      467.44],\n",
       "       [     258.19,      469.12],\n",
       "       [     258.19,      470.81],\n",
       "       [      256.5,       472.5],\n",
       "       [      256.5,      475.88],\n",
       "       [     254.81,      477.56],\n",
       "       [     254.81,      479.25],\n",
       "       [     236.25,      497.81],\n",
       "       [     234.56,      497.81],\n",
       "       [     231.19,      501.19],\n",
       "       [      229.5,      501.19],\n",
       "       [      229.5,      502.88],\n",
       "       [     227.81,      504.56],\n",
       "       [     227.81,         513],\n",
       "       [      229.5,      514.69],\n",
       "       [      229.5,      518.06],\n",
       "       [     231.19,      519.75],\n",
       "       [     231.19,      528.19],\n",
       "       [     232.88,      529.88],\n",
       "       [     232.88,      536.62],\n",
       "       [     234.56,      538.31],\n",
       "       [     234.56,      543.38],\n",
       "       [     232.88,      545.06],\n",
       "       [     232.88,      588.94],\n",
       "       [     234.56,      590.62],\n",
       "       [     234.56,      610.88],\n",
       "       [     232.88,      612.56],\n",
       "       [     232.88,      617.62],\n",
       "       [     231.19,      619.31],\n",
       "       [     231.19,      627.75],\n",
       "       [      229.5,      629.44],\n",
       "       [      229.5,      637.88],\n",
       "       [     227.81,      639.56],\n",
       "       [     227.81,      646.31],\n",
       "       [     226.12,         648],\n",
       "       [     226.12,      649.69],\n",
       "       [     224.44,      651.38],\n",
       "       [     219.38,      651.38],\n",
       "       [     219.38,      693.56],\n",
       "       [     224.44,      693.56],\n",
       "       [     227.81,      696.94],\n",
       "       [      229.5,      696.94],\n",
       "       [     231.19,      698.62],\n",
       "       [     232.88,      698.62],\n",
       "       [     236.25,         702],\n",
       "       [     236.25,      703.69],\n",
       "       [     239.62,      707.06],\n",
       "       [     239.62,      708.75],\n",
       "       [     241.31,      710.44],\n",
       "       [     241.31,         756],\n",
       "       [        243,      757.69],\n",
       "       [        243,      771.19],\n",
       "       [     244.69,      772.88],\n",
       "       [     244.69,         783],\n",
       "       [     246.38,      784.69],\n",
       "       [     246.38,      794.81],\n",
       "       [     248.06,       796.5],\n",
       "       [     248.06,      804.94],\n",
       "       [     249.75,      806.62],\n",
       "       [     249.75,      813.38],\n",
       "       [     251.44,      815.06],\n",
       "       [     251.44,      821.81],\n",
       "       [     253.12,       823.5],\n",
       "       [     253.12,      838.69],\n",
       "       [     251.44,      840.38],\n",
       "       [     251.44,      845.44],\n",
       "       [     253.12,      847.12],\n",
       "       [     253.12,       850.5],\n",
       "       [      256.5,      853.88],\n",
       "       [     258.19,      853.88],\n",
       "       [     261.56,      857.25],\n",
       "       [     263.25,      857.25],\n",
       "       [     266.62,      860.62],\n",
       "       [     266.62,      865.69],\n",
       "       [     288.56,      865.69],\n",
       "       [     288.56,      858.94],\n",
       "       [     291.94,      855.56],\n",
       "       [     291.94,       850.5],\n",
       "       [     290.25,      848.81],\n",
       "       [     290.25,      843.75],\n",
       "       [     288.56,      842.06],\n",
       "       [     288.56,         837],\n",
       "       [     286.88,      835.31],\n",
       "       [     286.88,       823.5],\n",
       "       [     288.56,      821.81],\n",
       "       [     288.56,      820.12],\n",
       "       [     290.25,      818.44],\n",
       "       [     290.25,      816.75],\n",
       "       [     293.62,      813.38],\n",
       "       [     293.62,      811.69],\n",
       "       [     291.94,         810],\n",
       "       [     291.94,      808.31],\n",
       "       [     290.25,      806.62],\n",
       "       [     290.25,      799.88],\n",
       "       [     288.56,      798.19],\n",
       "       [     288.56,      779.62],\n",
       "       [     290.25,      777.94],\n",
       "       [     290.25,      776.25],\n",
       "       [     293.62,      772.88],\n",
       "       [     293.62,      771.19],\n",
       "       [     307.12,      757.69],\n",
       "       [     307.12,         756],\n",
       "       [     313.88,      749.25],\n",
       "       [     313.88,      747.56],\n",
       "       [     329.06,      732.38],\n",
       "       [     329.06,      730.69],\n",
       "       [     330.75,         729],\n",
       "       [     330.75,      727.31],\n",
       "       [     332.44,      725.62],\n",
       "       [     332.44,      718.88],\n",
       "       [     334.12,      717.19],\n",
       "       [     334.12,      712.12],\n",
       "       [     332.44,      710.44],\n",
       "       [     332.44,         702],\n",
       "       [     330.75,      700.31],\n",
       "       [     330.75,      698.62],\n",
       "       [     332.44,      696.94],\n",
       "       [     332.44,      686.81],\n",
       "       [     334.12,      685.12],\n",
       "       [     334.12,      676.69],\n",
       "       [     332.44,         675],\n",
       "       [     332.44,      671.62],\n",
       "       [     330.75,      669.94],\n",
       "       [     330.75,      666.56],\n",
       "       [     329.06,      664.88],\n",
       "       [     329.06,      658.12],\n",
       "       [     327.38,      656.44],\n",
       "       [     329.06,      654.75],\n",
       "       [     329.06,         648],\n",
       "       [     327.38,      646.31],\n",
       "       [     327.38,      639.56],\n",
       "       [     329.06,      637.88],\n",
       "       [     329.06,       634.5],\n",
       "       [     327.38,      632.81],\n",
       "       [     327.38,      602.44],\n",
       "       [     325.69,      600.75],\n",
       "       [     325.69,      597.38],\n",
       "       [        324,      595.69],\n",
       "       [        324,      587.25],\n",
       "       [     322.31,      585.56],\n",
       "       [     322.31,      578.81],\n",
       "       [        324,      577.12],\n",
       "       [        324,      573.75],\n",
       "       [     330.75,         567],\n",
       "       [     332.44,         567],\n",
       "       [      337.5,      561.94],\n",
       "       [      337.5,      560.25],\n",
       "       [     340.88,      556.88],\n",
       "       [     340.88,      555.19],\n",
       "       [     342.56,       553.5],\n",
       "       [     342.56,      550.12],\n",
       "       [     344.25,      548.44],\n",
       "       [     344.25,      543.38],\n",
       "       [     342.56,      541.69],\n",
       "       [     342.56,      534.94],\n",
       "       [     340.88,      533.25],\n",
       "       [     340.88,      523.12],\n",
       "       [     339.19,      521.44],\n",
       "       [     339.19,         513],\n",
       "       [      337.5,      511.31],\n",
       "       [      337.5,      506.25],\n",
       "       [     335.81,      504.56],\n",
       "       [     335.81,      501.19],\n",
       "       [     334.12,       499.5],\n",
       "       [     334.12,      496.12],\n",
       "       [     332.44,      494.44],\n",
       "       [     332.44,      492.75],\n",
       "       [     330.75,      491.06],\n",
       "       [     330.75,      489.38],\n",
       "       [     320.62,      479.25],\n",
       "       [     318.94,      479.25],\n",
       "       [     315.56,      475.88],\n",
       "       [     313.88,      475.88],\n",
       "       [      310.5,       472.5],\n",
       "       [      310.5,      470.81],\n",
       "       [     308.81,      469.12],\n",
       "       [     308.81,      465.75],\n",
       "       [     307.12,      464.06],\n",
       "       [     307.12,         459],\n",
       "       [     308.81,      457.31],\n",
       "       [     308.81,      433.69],\n",
       "       [     307.12,         432],\n",
       "       [     307.12,      425.25],\n",
       "       [     305.44,      423.56],\n",
       "       [     305.44,      420.19],\n",
       "       [     303.75,       418.5],\n",
       "       [     303.75,      415.12],\n",
       "       [     302.06,      413.44],\n",
       "       [     302.06,      411.75],\n",
       "       [     298.69,      408.38],\n",
       "       [     298.69,      401.62]], dtype=float32), array([[      3.375,      253.12],\n",
       "       [      3.375,      332.44],\n",
       "       [     10.125,      332.44],\n",
       "       [     10.125,      325.69],\n",
       "       [     11.812,         324],\n",
       "       [       13.5,         324],\n",
       "       [     16.875,      320.62],\n",
       "       [     18.562,      320.62],\n",
       "       [     18.562,      318.94],\n",
       "       [     23.625,      313.88],\n",
       "       [     23.625,      312.19],\n",
       "       [     30.375,      305.44],\n",
       "       [     35.438,      305.44],\n",
       "       [     35.438,      275.06],\n",
       "       [     30.375,      275.06],\n",
       "       [     25.312,         270],\n",
       "       [     25.312,      268.31],\n",
       "       [     23.625,      266.62],\n",
       "       [     23.625,      264.94],\n",
       "       [     21.938,      263.25],\n",
       "       [     21.938,      261.56],\n",
       "       [      20.25,      259.88],\n",
       "       [      20.25,      253.12]], dtype=float32), array([[          0,      556.88],\n",
       "       [          0,      867.38],\n",
       "       [       6.75,      867.38],\n",
       "       [     8.4375,      869.06],\n",
       "       [     10.125,      867.38],\n",
       "       [     21.938,      867.38],\n",
       "       [     25.312,         864],\n",
       "       [         27,         864],\n",
       "       [     28.688,      862.31],\n",
       "       [     28.688,      857.25],\n",
       "       [         27,      855.56],\n",
       "       [         27,      853.88],\n",
       "       [     25.312,      852.19],\n",
       "       [     25.312,       850.5],\n",
       "       [     23.625,      848.81],\n",
       "       [     23.625,      847.12],\n",
       "       [     21.938,      845.44],\n",
       "       [     21.938,      842.06],\n",
       "       [      20.25,      840.38],\n",
       "       [      20.25,      808.31],\n",
       "       [     21.938,      806.62],\n",
       "       [     21.938,      799.88],\n",
       "       [     23.625,      798.19],\n",
       "       [     23.625,      757.69],\n",
       "       [     25.312,         756],\n",
       "       [     25.312,      754.31],\n",
       "       [         27,      752.62],\n",
       "       [     28.688,      752.62],\n",
       "       [     30.375,      750.94],\n",
       "       [     37.125,      750.94],\n",
       "       [     38.812,      752.62],\n",
       "       [     42.188,      752.62],\n",
       "       [     45.562,         756],\n",
       "       [     45.562,      766.12],\n",
       "       [      47.25,      767.81],\n",
       "       [      47.25,      774.56],\n",
       "       [     48.938,      776.25],\n",
       "       [     48.938,      779.62],\n",
       "       [     50.625,      781.31],\n",
       "       [     50.625,      786.38],\n",
       "       [     52.312,      786.38],\n",
       "       [     55.688,      789.75],\n",
       "       [     57.375,      789.75],\n",
       "       [     62.438,      784.69],\n",
       "       [     69.188,      791.44],\n",
       "       [     69.188,      789.75],\n",
       "       [     70.875,      788.06],\n",
       "       [     70.875,      764.44],\n",
       "       [     69.188,      762.75],\n",
       "       [     69.188,      757.69],\n",
       "       [       67.5,         756],\n",
       "       [       67.5,      750.94],\n",
       "       [     65.812,      749.25],\n",
       "       [     65.812,      740.81],\n",
       "       [     64.125,      739.12],\n",
       "       [     64.125,      730.69],\n",
       "       [     62.438,         729],\n",
       "       [     62.438,      722.25],\n",
       "       [      60.75,      720.56],\n",
       "       [      60.75,       715.5],\n",
       "       [     59.062,      713.81],\n",
       "       [     59.062,      712.12],\n",
       "       [     57.375,      710.44],\n",
       "       [     57.375,      707.06],\n",
       "       [     55.688,      705.38],\n",
       "       [     55.688,         702],\n",
       "       [         54,      700.31],\n",
       "       [         54,      696.94],\n",
       "       [     52.312,      695.25],\n",
       "       [     52.312,      693.56],\n",
       "       [     48.938,      690.19],\n",
       "       [     48.938,      686.81],\n",
       "       [      47.25,      685.12],\n",
       "       [      47.25,      683.44],\n",
       "       [     45.562,      681.75],\n",
       "       [     45.562,      678.38],\n",
       "       [     43.875,      676.69],\n",
       "       [     43.875,      673.31],\n",
       "       [     42.188,      671.62],\n",
       "       [     42.188,      669.94],\n",
       "       [       40.5,      668.25],\n",
       "       [       40.5,      666.56],\n",
       "       [     38.812,      664.88],\n",
       "       [     38.812,      663.19],\n",
       "       [     37.125,       661.5],\n",
       "       [     37.125,      659.81],\n",
       "       [     35.438,      658.12],\n",
       "       [     35.438,      654.75],\n",
       "       [      33.75,      653.06],\n",
       "       [      33.75,      651.38],\n",
       "       [     32.062,      649.69],\n",
       "       [     32.062,      646.31],\n",
       "       [     30.375,      644.62],\n",
       "       [     30.375,      641.25],\n",
       "       [     28.688,      639.56],\n",
       "       [     28.688,      637.88],\n",
       "       [         27,      636.19],\n",
       "       [         27,       634.5],\n",
       "       [     25.312,      632.81],\n",
       "       [     25.312,      631.12],\n",
       "       [     23.625,      629.44],\n",
       "       [     23.625,      626.06],\n",
       "       [     21.938,      624.38],\n",
       "       [     21.938,         621],\n",
       "       [      20.25,      619.31],\n",
       "       [      20.25,      609.19],\n",
       "       [     18.562,       607.5],\n",
       "       [     18.562,      600.75],\n",
       "       [     16.875,      599.06],\n",
       "       [     16.875,         594],\n",
       "       [     15.188,      592.31],\n",
       "       [     15.188,      588.94],\n",
       "       [       13.5,      587.25],\n",
       "       [       13.5,      583.88],\n",
       "       [     11.812,      582.19],\n",
       "       [     11.812,      572.06],\n",
       "       [     10.125,      570.38],\n",
       "       [     10.125,      556.88]], dtype=float32)]\n",
       "xyn: [array([[    0.22917,     0.21563],\n",
       "       [    0.22917,     0.22031],\n",
       "       [    0.22708,     0.22187],\n",
       "       ...,\n",
       "       [    0.50625,     0.22187],\n",
       "       [    0.50417,     0.22031],\n",
       "       [    0.50417,     0.21563]], shape=(669, 2), dtype=float32), array([[    0.99375,     0.36719],\n",
       "       [    0.99167,     0.36875],\n",
       "       [    0.98958,     0.36875],\n",
       "       [     0.9875,     0.37031],\n",
       "       [    0.98542,     0.37031],\n",
       "       [    0.98333,     0.37187],\n",
       "       [    0.98333,     0.37344],\n",
       "       [    0.97708,     0.37813],\n",
       "       [    0.97708,     0.38125],\n",
       "       [      0.975,     0.38281],\n",
       "       [      0.975,      0.3875],\n",
       "       [    0.97292,     0.38906],\n",
       "       [    0.97292,     0.41406],\n",
       "       [      0.975,     0.41563],\n",
       "       [      0.975,     0.42031],\n",
       "       [    0.97708,     0.42188],\n",
       "       [    0.97708,     0.43437],\n",
       "       [      0.975,     0.43594],\n",
       "       [      0.975,     0.43906],\n",
       "       [    0.97292,     0.44063],\n",
       "       [    0.97292,     0.44375],\n",
       "       [    0.97083,     0.44531],\n",
       "       [    0.97083,     0.44688],\n",
       "       [    0.96667,        0.45],\n",
       "       [    0.96667,     0.45156],\n",
       "       [    0.96458,     0.45312],\n",
       "       [    0.96458,     0.45469],\n",
       "       [     0.9625,     0.45625],\n",
       "       [     0.9625,     0.45781],\n",
       "       [    0.95833,     0.46094],\n",
       "       [    0.95833,      0.4625],\n",
       "       [    0.95625,     0.46406],\n",
       "       [    0.95625,     0.46875],\n",
       "       [    0.95417,     0.47031],\n",
       "       [    0.95417,     0.47969],\n",
       "       [    0.95208,     0.48125],\n",
       "       [    0.95208,     0.49687],\n",
       "       [       0.95,     0.49844],\n",
       "       [       0.95,     0.50313],\n",
       "       [    0.94167,     0.50937],\n",
       "       [    0.93958,     0.50937],\n",
       "       [     0.9375,     0.51094],\n",
       "       [    0.93542,     0.51094],\n",
       "       [    0.93333,     0.50937],\n",
       "       [    0.91458,     0.50937],\n",
       "       [    0.90833,     0.51406],\n",
       "       [    0.91458,     0.51875],\n",
       "       [    0.91667,     0.51875],\n",
       "       [    0.91875,     0.52031],\n",
       "       [    0.91875,     0.52188],\n",
       "       [    0.92083,     0.52344],\n",
       "       [    0.92083,     0.52812],\n",
       "       [    0.92292,     0.52969],\n",
       "       [    0.92292,     0.53125],\n",
       "       [      0.925,     0.53281],\n",
       "       [      0.925,     0.53438],\n",
       "       [    0.92708,     0.53594],\n",
       "       [    0.92708,      0.5375],\n",
       "       [    0.94167,     0.54844],\n",
       "       [    0.94167,     0.55156],\n",
       "       [    0.94375,     0.55313],\n",
       "       [    0.94375,     0.56094],\n",
       "       [    0.94167,      0.5625],\n",
       "       [    0.94167,     0.57187],\n",
       "       [    0.93958,     0.57344],\n",
       "       [    0.93958,     0.57812],\n",
       "       [     0.9375,     0.57969],\n",
       "       [     0.9375,     0.58281],\n",
       "       [    0.93542,     0.58438],\n",
       "       [    0.93542,     0.58906],\n",
       "       [    0.93333,     0.59062],\n",
       "       [    0.93333,     0.59375],\n",
       "       [    0.93125,     0.59531],\n",
       "       [    0.93125,     0.59844],\n",
       "       [    0.92917,         0.6],\n",
       "       [    0.92917,     0.60469],\n",
       "       [    0.92708,     0.60625],\n",
       "       [    0.92708,     0.61563],\n",
       "       [      0.925,     0.61719],\n",
       "       [      0.925,     0.62187],\n",
       "       [    0.92292,     0.62344],\n",
       "       [    0.92292,     0.63125],\n",
       "       [      0.925,     0.63281],\n",
       "       [      0.925,     0.63437],\n",
       "       [    0.92917,      0.6375],\n",
       "       [    0.92917,     0.64844],\n",
       "       [    0.92708,        0.65],\n",
       "       [    0.92708,     0.65312],\n",
       "       [      0.925,     0.65469],\n",
       "       [      0.925,     0.65625],\n",
       "       [    0.92292,     0.65781],\n",
       "       [    0.92292,     0.66094],\n",
       "       [    0.92083,      0.6625],\n",
       "       [    0.92083,     0.66562],\n",
       "       [    0.91875,     0.66719],\n",
       "       [    0.91875,     0.66875],\n",
       "       [    0.91667,     0.67031],\n",
       "       [    0.91667,     0.67344],\n",
       "       [    0.91458,       0.675],\n",
       "       [    0.91458,     0.67969],\n",
       "       [     0.9125,     0.68125],\n",
       "       [     0.9125,     0.68906],\n",
       "       [    0.91042,     0.69063],\n",
       "       [    0.91042,     0.69531],\n",
       "       [    0.90833,     0.69687],\n",
       "       [    0.90833,         0.7],\n",
       "       [    0.90625,     0.70156],\n",
       "       [    0.90625,     0.70625],\n",
       "       [    0.90417,     0.70781],\n",
       "       [    0.90417,     0.70938],\n",
       "       [    0.90208,     0.71094],\n",
       "       [    0.90208,     0.71406],\n",
       "       [        0.9,     0.71562],\n",
       "       [        0.9,     0.71719],\n",
       "       [    0.89792,     0.71875],\n",
       "       [    0.89792,     0.72188],\n",
       "       [    0.89583,     0.72344],\n",
       "       [    0.89583,     0.72656],\n",
       "       [    0.89375,     0.72812],\n",
       "       [    0.89375,     0.72969],\n",
       "       [    0.89167,     0.73125],\n",
       "       [    0.89167,     0.73281],\n",
       "       [    0.88958,     0.73438],\n",
       "       [    0.88958,     0.73906],\n",
       "       [     0.8875,     0.74063],\n",
       "       [     0.8875,     0.74219],\n",
       "       [    0.88333,     0.74531],\n",
       "       [    0.88333,     0.74687],\n",
       "       [    0.88125,     0.74844],\n",
       "       [    0.88125,     0.75156],\n",
       "       [    0.87917,     0.75313],\n",
       "       [    0.87917,     0.75469],\n",
       "       [    0.86875,      0.7625],\n",
       "       [    0.86458,      0.7625],\n",
       "       [     0.8625,     0.76406],\n",
       "       [    0.85208,     0.76406],\n",
       "       [       0.85,      0.7625],\n",
       "       [    0.82917,      0.7625],\n",
       "       [    0.82917,     0.78281],\n",
       "       [     0.8375,     0.78281],\n",
       "       [    0.84375,      0.7875],\n",
       "       [    0.84583,      0.7875],\n",
       "       [       0.85,     0.79062],\n",
       "       [    0.85208,     0.79062],\n",
       "       [    0.85417,     0.79219],\n",
       "       [    0.85625,     0.79219],\n",
       "       [    0.85833,     0.79375],\n",
       "       [    0.86042,     0.79375],\n",
       "       [     0.8625,     0.79531],\n",
       "       [    0.86458,     0.79531],\n",
       "       [    0.86667,     0.79688],\n",
       "       [    0.86875,     0.79688],\n",
       "       [    0.87292,         0.8],\n",
       "       [      0.875,         0.8],\n",
       "       [    0.87708,     0.80156],\n",
       "       [    0.87917,     0.80156],\n",
       "       [    0.88333,     0.80469],\n",
       "       [    0.88542,     0.80469],\n",
       "       [    0.88958,     0.80781],\n",
       "       [    0.88958,     0.81406],\n",
       "       [    0.90833,     0.81406],\n",
       "       [    0.90833,     0.80937],\n",
       "       [    0.91042,     0.80781],\n",
       "       [    0.91042,     0.80625],\n",
       "       [     0.9125,     0.80469],\n",
       "       [     0.9125,     0.80313],\n",
       "       [    0.91458,     0.80156],\n",
       "       [    0.91458,     0.79688],\n",
       "       [    0.91667,     0.79531],\n",
       "       [    0.91667,     0.78594],\n",
       "       [    0.91875,     0.78438],\n",
       "       [    0.91875,     0.78125],\n",
       "       [    0.92083,     0.77969],\n",
       "       [    0.92083,     0.77656],\n",
       "       [    0.92292,       0.775],\n",
       "       [    0.92292,     0.77188],\n",
       "       [      0.925,     0.77031],\n",
       "       [      0.925,     0.76562],\n",
       "       [    0.93125,     0.76094],\n",
       "       [    0.93125,     0.75937],\n",
       "       [    0.93333,     0.75781],\n",
       "       [    0.93333,     0.75469],\n",
       "       [     0.9375,     0.75156],\n",
       "       [     0.9375,        0.75],\n",
       "       [    0.93958,     0.74844],\n",
       "       [    0.93958,     0.74531],\n",
       "       [    0.94167,     0.74375],\n",
       "       [    0.94167,     0.74063],\n",
       "       [    0.94583,      0.7375],\n",
       "       [    0.94583,     0.73594],\n",
       "       [    0.94792,     0.73438],\n",
       "       [    0.94792,     0.73281],\n",
       "       [       0.95,     0.73125],\n",
       "       [       0.95,     0.72969],\n",
       "       [    0.95208,     0.72812],\n",
       "       [    0.95208,       0.725],\n",
       "       [    0.95417,     0.72344],\n",
       "       [    0.95417,     0.72188],\n",
       "       [    0.95625,     0.72031],\n",
       "       [    0.95625,     0.71719],\n",
       "       [    0.95833,     0.71562],\n",
       "       [    0.95833,      0.7125],\n",
       "       [    0.96042,     0.71094],\n",
       "       [    0.96042,     0.70781],\n",
       "       [     0.9625,     0.70625],\n",
       "       [     0.9625,     0.70469],\n",
       "       [    0.96458,     0.70312],\n",
       "       [    0.96458,     0.70156],\n",
       "       [    0.96667,         0.7],\n",
       "       [    0.96667,     0.69687],\n",
       "       [    0.96875,     0.69531],\n",
       "       [    0.96875,     0.69375],\n",
       "       [    0.97083,     0.69219],\n",
       "       [    0.97083,     0.69063],\n",
       "       [    0.97292,     0.68906],\n",
       "       [    0.97292,      0.6875],\n",
       "       [      0.975,     0.68594],\n",
       "       [      0.975,     0.68437],\n",
       "       [    0.97708,     0.68281],\n",
       "       [    0.97708,     0.68125],\n",
       "       [    0.97917,     0.67969],\n",
       "       [    0.97917,     0.67813],\n",
       "       [    0.98333,       0.675],\n",
       "       [    0.98333,     0.67344],\n",
       "       [    0.98542,     0.67188],\n",
       "       [    0.98542,     0.67031],\n",
       "       [    0.98958,     0.66719],\n",
       "       [    0.98958,     0.66562],\n",
       "       [    0.99167,     0.66406],\n",
       "       [    0.99167,      0.6625],\n",
       "       [    0.99583,     0.65938],\n",
       "       [    0.99792,     0.65938],\n",
       "       [    0.99792,     0.36719]], dtype=float32), array([[      0.125,     0.36562],\n",
       "       [      0.125,     0.37187],\n",
       "       [    0.12292,     0.37344],\n",
       "       [    0.12292,     0.37656],\n",
       "       [    0.12083,     0.37813],\n",
       "       [    0.12083,     0.38281],\n",
       "       [    0.11875,     0.38438],\n",
       "       [    0.11875,     0.39531],\n",
       "       [    0.11667,     0.39687],\n",
       "       [    0.11667,     0.42031],\n",
       "       [    0.11458,     0.42188],\n",
       "       [    0.11458,     0.42812],\n",
       "       [     0.1125,     0.42969],\n",
       "       [     0.1125,     0.43125],\n",
       "       [   0.097917,     0.44219],\n",
       "       [   0.095833,     0.44219],\n",
       "       [   0.085417,        0.45],\n",
       "       [   0.085417,     0.45156],\n",
       "       [   0.083333,     0.45312],\n",
       "       [   0.083333,     0.45469],\n",
       "       [   0.079167,     0.45781],\n",
       "       [   0.079167,     0.45937],\n",
       "       [   0.077083,     0.46094],\n",
       "       [   0.077083,     0.46562],\n",
       "       [      0.075,     0.46719],\n",
       "       [      0.075,     0.48281],\n",
       "       [   0.077083,     0.48438],\n",
       "       [   0.077083,     0.50313],\n",
       "       [      0.075,     0.50469],\n",
       "       [      0.075,     0.50937],\n",
       "       [   0.072917,     0.51094],\n",
       "       [   0.072917,     0.52031],\n",
       "       [      0.075,     0.52188],\n",
       "       [      0.075,       0.525],\n",
       "       [   0.077083,     0.52656],\n",
       "       [   0.077083,     0.53281],\n",
       "       [   0.079167,     0.53438],\n",
       "       [   0.079167,     0.54688],\n",
       "       [   0.077083,     0.54844],\n",
       "       [   0.077083,       0.575],\n",
       "       [      0.075,     0.57656],\n",
       "       [      0.075,     0.59375],\n",
       "       [   0.072917,     0.59531],\n",
       "       [   0.072917,     0.63125],\n",
       "       [      0.075,     0.63281],\n",
       "       [      0.075,     0.64062],\n",
       "       [   0.077083,     0.64219],\n",
       "       [   0.077083,     0.64375],\n",
       "       [   0.079167,     0.64531],\n",
       "       [   0.079167,     0.64688],\n",
       "       [   0.083333,        0.65],\n",
       "       [   0.083333,     0.65156],\n",
       "       [   0.085417,     0.65312],\n",
       "       [   0.085417,     0.65469],\n",
       "       [     0.0875,     0.65625],\n",
       "       [     0.0875,     0.69531],\n",
       "       [   0.089583,     0.69687],\n",
       "       [   0.089583,     0.70625],\n",
       "       [   0.091667,     0.70781],\n",
       "       [   0.091667,     0.71562],\n",
       "       [    0.09375,     0.71719],\n",
       "       [    0.09375,     0.72812],\n",
       "       [   0.091667,     0.72969],\n",
       "       [   0.091667,     0.73281],\n",
       "       [   0.089583,     0.73438],\n",
       "       [   0.089583,      0.7375],\n",
       "       [     0.0875,     0.73906],\n",
       "       [     0.0875,     0.74063],\n",
       "       [   0.077083,     0.74844],\n",
       "       [   0.077083,        0.75],\n",
       "       [   0.072917,     0.75313],\n",
       "       [   0.072917,     0.76094],\n",
       "       [   0.070833,      0.7625],\n",
       "       [   0.070833,     0.77031],\n",
       "       [    0.06875,     0.77188],\n",
       "       [     0.0625,     0.77188],\n",
       "       [     0.0625,       0.825],\n",
       "       [   0.072917,       0.825],\n",
       "       [   0.077083,     0.82812],\n",
       "       [   0.079167,     0.82812],\n",
       "       [    0.08125,     0.82969],\n",
       "       [   0.083333,     0.82969],\n",
       "       [   0.085417,     0.83125],\n",
       "       [     0.0875,     0.83125],\n",
       "       [   0.089583,     0.83281],\n",
       "       [    0.09375,     0.83281],\n",
       "       [   0.095833,     0.83438],\n",
       "       [    0.11667,     0.83438],\n",
       "       [    0.11875,     0.83281],\n",
       "       [    0.12083,     0.83281],\n",
       "       [      0.125,     0.82969],\n",
       "       [      0.125,     0.82812],\n",
       "       [    0.12708,     0.82656],\n",
       "       [    0.12708,     0.82031],\n",
       "       [      0.125,     0.81875],\n",
       "       [      0.125,     0.81719],\n",
       "       [    0.12292,     0.81563],\n",
       "       [    0.12292,     0.81406],\n",
       "       [    0.12083,      0.8125],\n",
       "       [    0.12083,     0.81094],\n",
       "       [    0.11667,     0.80781],\n",
       "       [    0.11667,     0.80625],\n",
       "       [    0.11458,     0.80469],\n",
       "       [    0.11458,     0.80313],\n",
       "       [     0.1125,     0.80156],\n",
       "       [     0.1125,         0.8],\n",
       "       [    0.10833,     0.79688],\n",
       "       [    0.10833,     0.77656],\n",
       "       [    0.11042,       0.775],\n",
       "       [    0.11042,     0.77188],\n",
       "       [     0.1125,     0.77031],\n",
       "       [     0.1125,     0.76094],\n",
       "       [    0.11458,     0.75937],\n",
       "       [    0.11458,     0.74687],\n",
       "       [    0.11667,     0.74531],\n",
       "       [    0.11667,      0.7375],\n",
       "       [    0.11875,     0.73594],\n",
       "       [    0.11875,     0.73281],\n",
       "       [    0.12083,     0.73125],\n",
       "       [    0.12083,     0.72812],\n",
       "       [    0.12292,     0.72656],\n",
       "       [    0.12292,     0.72344],\n",
       "       [      0.125,     0.72188],\n",
       "       [      0.125,     0.71875],\n",
       "       [    0.12708,     0.71719],\n",
       "       [    0.12708,     0.71562],\n",
       "       [    0.12917,     0.71406],\n",
       "       [    0.12917,      0.7125],\n",
       "       [    0.13125,     0.71094],\n",
       "       [    0.13125,     0.70938],\n",
       "       [    0.13333,     0.70781],\n",
       "       [    0.13333,     0.70156],\n",
       "       [    0.13542,         0.7],\n",
       "       [    0.13542,     0.68906],\n",
       "       [     0.1375,      0.6875],\n",
       "       [     0.1375,     0.68125],\n",
       "       [    0.13958,     0.67969],\n",
       "       [    0.13958,     0.67344],\n",
       "       [    0.14167,     0.67188],\n",
       "       [    0.14167,     0.66875],\n",
       "       [    0.14792,     0.66406],\n",
       "       [       0.15,     0.66406],\n",
       "       [    0.15208,      0.6625],\n",
       "       [    0.15417,      0.6625],\n",
       "       [     0.1625,     0.66875],\n",
       "       [     0.1625,     0.67188],\n",
       "       [    0.16458,     0.67344],\n",
       "       [    0.16458,      0.6875],\n",
       "       [    0.16667,     0.68906],\n",
       "       [    0.16667,     0.69063],\n",
       "       [    0.17292,     0.69531],\n",
       "       [    0.17292,     0.69687],\n",
       "       [      0.175,     0.69844],\n",
       "       [      0.175,         0.7],\n",
       "       [    0.17917,     0.70312],\n",
       "       [    0.17917,     0.70469],\n",
       "       [    0.18125,     0.70625],\n",
       "       [    0.18125,     0.70938],\n",
       "       [    0.18333,     0.71094],\n",
       "       [    0.18333,     0.71406],\n",
       "       [    0.18542,     0.71562],\n",
       "       [    0.18542,     0.71875],\n",
       "       [     0.1875,     0.72031],\n",
       "       [     0.1875,     0.72656],\n",
       "       [    0.18958,     0.72812],\n",
       "       [    0.18958,     0.73594],\n",
       "       [    0.19167,      0.7375],\n",
       "       [    0.19167,     0.74063],\n",
       "       [    0.19375,     0.74219],\n",
       "       [    0.19375,     0.74687],\n",
       "       [    0.19583,     0.74844],\n",
       "       [    0.19583,     0.75313],\n",
       "       [    0.19792,     0.75469],\n",
       "       [    0.19792,      0.7625],\n",
       "       [        0.2,     0.76406],\n",
       "       [        0.2,     0.76719],\n",
       "       [    0.20208,     0.76875],\n",
       "       [    0.20208,     0.77031],\n",
       "       [    0.20417,     0.77188],\n",
       "       [    0.20417,     0.77656],\n",
       "       [    0.20625,     0.77812],\n",
       "       [    0.20625,     0.78438],\n",
       "       [    0.20833,     0.78594],\n",
       "       [    0.20833,     0.78906],\n",
       "       [    0.21042,     0.79062],\n",
       "       [    0.21042,     0.79219],\n",
       "       [     0.2125,     0.79375],\n",
       "       [     0.2125,     0.79688],\n",
       "       [    0.21458,     0.79844],\n",
       "       [    0.21458,     0.81719],\n",
       "       [    0.21667,     0.81875],\n",
       "       [    0.21667,       0.825],\n",
       "       [    0.21875,     0.82656],\n",
       "       [    0.21875,     0.82812],\n",
       "       [    0.22083,     0.82969],\n",
       "       [    0.25417,     0.82969],\n",
       "       [    0.25625,     0.82812],\n",
       "       [     0.2625,     0.82812],\n",
       "       [    0.26458,     0.82656],\n",
       "       [    0.27083,     0.82656],\n",
       "       [    0.27292,       0.825],\n",
       "       [    0.27917,       0.825],\n",
       "       [    0.28125,     0.82344],\n",
       "       [    0.28333,     0.82344],\n",
       "       [    0.28542,     0.82187],\n",
       "       [     0.2875,     0.82187],\n",
       "       [    0.28958,     0.82031],\n",
       "       [    0.28958,     0.81719],\n",
       "       [    0.29167,     0.81563],\n",
       "       [    0.29167,     0.81406],\n",
       "       [     0.2875,     0.81094],\n",
       "       [     0.2875,     0.80937],\n",
       "       [    0.28542,     0.80781],\n",
       "       [    0.28125,     0.80781],\n",
       "       [    0.25625,     0.78906],\n",
       "       [    0.25625,      0.7875],\n",
       "       [    0.25417,     0.78594],\n",
       "       [    0.25417,     0.78438],\n",
       "       [    0.25208,     0.78281],\n",
       "       [    0.25208,     0.77812],\n",
       "       [       0.25,     0.77656],\n",
       "       [       0.25,     0.77188],\n",
       "       [    0.24792,     0.77031],\n",
       "       [    0.24792,     0.76406],\n",
       "       [    0.24583,      0.7625],\n",
       "       [    0.24583,     0.75937],\n",
       "       [    0.24375,     0.75781],\n",
       "       [    0.24375,        0.75],\n",
       "       [    0.24167,     0.74844],\n",
       "       [    0.24167,     0.73594],\n",
       "       [    0.23958,     0.73438],\n",
       "       [    0.23958,     0.72656],\n",
       "       [     0.2375,       0.725],\n",
       "       [     0.2375,     0.72188],\n",
       "       [    0.23542,     0.72031],\n",
       "       [    0.23542,      0.7125],\n",
       "       [    0.23333,     0.71094],\n",
       "       [    0.23333,     0.69844],\n",
       "       [    0.23125,     0.69687],\n",
       "       [    0.23125,     0.68281],\n",
       "       [    0.22917,     0.68125],\n",
       "       [    0.22917,       0.675],\n",
       "       [    0.22708,     0.67344],\n",
       "       [    0.22708,     0.66719],\n",
       "       [      0.225,     0.66562],\n",
       "       [      0.225,     0.64531],\n",
       "       [    0.22708,     0.64375],\n",
       "       [    0.22708,     0.64219],\n",
       "       [     0.2375,     0.63437],\n",
       "       [     0.2375,     0.61719],\n",
       "       [    0.23542,     0.61563],\n",
       "       [    0.23542,     0.60781],\n",
       "       [    0.23333,     0.60625],\n",
       "       [    0.23333,     0.60156],\n",
       "       [    0.23125,         0.6],\n",
       "       [    0.23125,     0.59531],\n",
       "       [    0.22917,     0.59375],\n",
       "       [    0.22917,      0.5875],\n",
       "       [    0.22708,     0.58594],\n",
       "       [    0.22708,     0.57969],\n",
       "       [      0.225,     0.57812],\n",
       "       [      0.225,     0.57031],\n",
       "       [    0.22292,     0.56875],\n",
       "       [    0.22292,     0.55937],\n",
       "       [    0.22708,     0.55625],\n",
       "       [    0.22708,     0.55469],\n",
       "       [    0.24583,     0.54062],\n",
       "       [    0.24583,     0.53906],\n",
       "       [    0.24792,      0.5375],\n",
       "       [    0.24792,     0.53125],\n",
       "       [       0.25,     0.52969],\n",
       "       [       0.25,     0.52031],\n",
       "       [    0.24792,     0.51875],\n",
       "       [    0.24792,     0.51406],\n",
       "       [    0.24583,      0.5125],\n",
       "       [    0.24583,     0.51094],\n",
       "       [    0.24375,     0.50937],\n",
       "       [    0.24375,     0.50781],\n",
       "       [    0.23958,     0.50469],\n",
       "       [    0.23958,     0.50313],\n",
       "       [    0.23542,         0.5],\n",
       "       [    0.23542,     0.49844],\n",
       "       [    0.23333,     0.49687],\n",
       "       [    0.23333,     0.49531],\n",
       "       [    0.23125,     0.49375],\n",
       "       [    0.23125,     0.49219],\n",
       "       [    0.22917,     0.49062],\n",
       "       [    0.22917,     0.48594],\n",
       "       [    0.22708,     0.48438],\n",
       "       [    0.22708,     0.47813],\n",
       "       [      0.225,     0.47656],\n",
       "       [      0.225,     0.46875],\n",
       "       [    0.22292,     0.46719],\n",
       "       [    0.22292,     0.46406],\n",
       "       [    0.22083,      0.4625],\n",
       "       [    0.22083,     0.46094],\n",
       "       [    0.21667,     0.45781],\n",
       "       [    0.21667,     0.45625],\n",
       "       [     0.2125,     0.45312],\n",
       "       [     0.2125,     0.45156],\n",
       "       [    0.20833,     0.44844],\n",
       "       [    0.20833,     0.44688],\n",
       "       [        0.2,     0.44063],\n",
       "       [        0.2,     0.43906],\n",
       "       [    0.18958,     0.43125],\n",
       "       [    0.18958,     0.42969],\n",
       "       [     0.1875,     0.42812],\n",
       "       [     0.1875,     0.42031],\n",
       "       [    0.18958,     0.41875],\n",
       "       [    0.18958,      0.4125],\n",
       "       [    0.19167,     0.41094],\n",
       "       [    0.19167,       0.375],\n",
       "       [    0.18958,     0.37344],\n",
       "       [    0.18958,     0.37187],\n",
       "       [     0.1875,     0.37031],\n",
       "       [     0.1875,     0.36562]], dtype=float32), array([[    0.32708,     0.37187],\n",
       "       [    0.32708,     0.37813],\n",
       "       [      0.325,     0.37969],\n",
       "       [      0.325,     0.38125],\n",
       "       [    0.32292,     0.38281],\n",
       "       [    0.32292,      0.3875],\n",
       "       [    0.32083,     0.38906],\n",
       "       [    0.32083,     0.39375],\n",
       "       [    0.31875,     0.39531],\n",
       "       [    0.31875,     0.40781],\n",
       "       [    0.32083,     0.40938],\n",
       "       [    0.32083,     0.41563],\n",
       "       [    0.32292,     0.41719],\n",
       "       [    0.32292,       0.425],\n",
       "       [      0.325,     0.42656],\n",
       "       [    0.32292,     0.42812],\n",
       "       [    0.32292,     0.42969],\n",
       "       [    0.32083,     0.43125],\n",
       "       [    0.32083,     0.43281],\n",
       "       [    0.31875,     0.43437],\n",
       "       [    0.31875,     0.43594],\n",
       "       [    0.31667,      0.4375],\n",
       "       [    0.31667,     0.44063],\n",
       "       [    0.31458,     0.44219],\n",
       "       [    0.31458,     0.44375],\n",
       "       [    0.29167,     0.46094],\n",
       "       [    0.28958,     0.46094],\n",
       "       [    0.28542,     0.46406],\n",
       "       [    0.28333,     0.46406],\n",
       "       [    0.28333,     0.46562],\n",
       "       [    0.28125,     0.46719],\n",
       "       [    0.28125,       0.475],\n",
       "       [    0.28333,     0.47656],\n",
       "       [    0.28333,     0.47969],\n",
       "       [    0.28542,     0.48125],\n",
       "       [    0.28542,     0.48906],\n",
       "       [     0.2875,     0.49062],\n",
       "       [     0.2875,     0.49687],\n",
       "       [    0.28958,     0.49844],\n",
       "       [    0.28958,     0.50313],\n",
       "       [     0.2875,     0.50469],\n",
       "       [     0.2875,     0.54531],\n",
       "       [    0.28958,     0.54688],\n",
       "       [    0.28958,     0.56563],\n",
       "       [     0.2875,     0.56719],\n",
       "       [     0.2875,     0.57187],\n",
       "       [    0.28542,     0.57344],\n",
       "       [    0.28542,     0.58125],\n",
       "       [    0.28333,     0.58281],\n",
       "       [    0.28333,     0.59062],\n",
       "       [    0.28125,     0.59219],\n",
       "       [    0.28125,     0.59844],\n",
       "       [    0.27917,         0.6],\n",
       "       [    0.27917,     0.60156],\n",
       "       [    0.27708,     0.60312],\n",
       "       [    0.27083,     0.60312],\n",
       "       [    0.27083,     0.64219],\n",
       "       [    0.27708,     0.64219],\n",
       "       [    0.28125,     0.64531],\n",
       "       [    0.28333,     0.64531],\n",
       "       [    0.28542,     0.64688],\n",
       "       [     0.2875,     0.64688],\n",
       "       [    0.29167,        0.65],\n",
       "       [    0.29167,     0.65156],\n",
       "       [    0.29583,     0.65469],\n",
       "       [    0.29583,     0.65625],\n",
       "       [    0.29792,     0.65781],\n",
       "       [    0.29792,         0.7],\n",
       "       [        0.3,     0.70156],\n",
       "       [        0.3,     0.71406],\n",
       "       [    0.30208,     0.71562],\n",
       "       [    0.30208,       0.725],\n",
       "       [    0.30417,     0.72656],\n",
       "       [    0.30417,     0.73594],\n",
       "       [    0.30625,      0.7375],\n",
       "       [    0.30625,     0.74531],\n",
       "       [    0.30833,     0.74687],\n",
       "       [    0.30833,     0.75313],\n",
       "       [    0.31042,     0.75469],\n",
       "       [    0.31042,     0.76094],\n",
       "       [     0.3125,      0.7625],\n",
       "       [     0.3125,     0.77656],\n",
       "       [    0.31042,     0.77812],\n",
       "       [    0.31042,     0.78281],\n",
       "       [     0.3125,     0.78438],\n",
       "       [     0.3125,      0.7875],\n",
       "       [    0.31667,     0.79062],\n",
       "       [    0.31875,     0.79062],\n",
       "       [    0.32292,     0.79375],\n",
       "       [      0.325,     0.79375],\n",
       "       [    0.32917,     0.79688],\n",
       "       [    0.32917,     0.80156],\n",
       "       [    0.35625,     0.80156],\n",
       "       [    0.35625,     0.79531],\n",
       "       [    0.36042,     0.79219],\n",
       "       [    0.36042,      0.7875],\n",
       "       [    0.35833,     0.78594],\n",
       "       [    0.35833,     0.78125],\n",
       "       [    0.35625,     0.77969],\n",
       "       [    0.35625,       0.775],\n",
       "       [    0.35417,     0.77344],\n",
       "       [    0.35417,      0.7625],\n",
       "       [    0.35625,     0.76094],\n",
       "       [    0.35625,     0.75937],\n",
       "       [    0.35833,     0.75781],\n",
       "       [    0.35833,     0.75625],\n",
       "       [     0.3625,     0.75313],\n",
       "       [     0.3625,     0.75156],\n",
       "       [    0.36042,        0.75],\n",
       "       [    0.36042,     0.74844],\n",
       "       [    0.35833,     0.74687],\n",
       "       [    0.35833,     0.74063],\n",
       "       [    0.35625,     0.73906],\n",
       "       [    0.35625,     0.72188],\n",
       "       [    0.35833,     0.72031],\n",
       "       [    0.35833,     0.71875],\n",
       "       [     0.3625,     0.71562],\n",
       "       [     0.3625,     0.71406],\n",
       "       [    0.37917,     0.70156],\n",
       "       [    0.37917,         0.7],\n",
       "       [     0.3875,     0.69375],\n",
       "       [     0.3875,     0.69219],\n",
       "       [    0.40625,     0.67813],\n",
       "       [    0.40625,     0.67656],\n",
       "       [    0.40833,       0.675],\n",
       "       [    0.40833,     0.67344],\n",
       "       [    0.41042,     0.67188],\n",
       "       [    0.41042,     0.66562],\n",
       "       [     0.4125,     0.66406],\n",
       "       [     0.4125,     0.65938],\n",
       "       [    0.41042,     0.65781],\n",
       "       [    0.41042,        0.65],\n",
       "       [    0.40833,     0.64844],\n",
       "       [    0.40833,     0.64688],\n",
       "       [    0.41042,     0.64531],\n",
       "       [    0.41042,     0.63594],\n",
       "       [     0.4125,     0.63437],\n",
       "       [     0.4125,     0.62656],\n",
       "       [    0.41042,       0.625],\n",
       "       [    0.41042,     0.62187],\n",
       "       [    0.40833,     0.62031],\n",
       "       [    0.40833,     0.61719],\n",
       "       [    0.40625,     0.61563],\n",
       "       [    0.40625,     0.60938],\n",
       "       [    0.40417,     0.60781],\n",
       "       [    0.40625,     0.60625],\n",
       "       [    0.40625,         0.6],\n",
       "       [    0.40417,     0.59844],\n",
       "       [    0.40417,     0.59219],\n",
       "       [    0.40625,     0.59062],\n",
       "       [    0.40625,      0.5875],\n",
       "       [    0.40417,     0.58594],\n",
       "       [    0.40417,     0.55781],\n",
       "       [    0.40208,     0.55625],\n",
       "       [    0.40208,     0.55313],\n",
       "       [        0.4,     0.55156],\n",
       "       [        0.4,     0.54375],\n",
       "       [    0.39792,     0.54219],\n",
       "       [    0.39792,     0.53594],\n",
       "       [        0.4,     0.53438],\n",
       "       [        0.4,     0.53125],\n",
       "       [    0.40833,       0.525],\n",
       "       [    0.41042,       0.525],\n",
       "       [    0.41667,     0.52031],\n",
       "       [    0.41667,     0.51875],\n",
       "       [    0.42083,     0.51562],\n",
       "       [    0.42083,     0.51406],\n",
       "       [    0.42292,      0.5125],\n",
       "       [    0.42292,     0.50937],\n",
       "       [      0.425,     0.50781],\n",
       "       [      0.425,     0.50313],\n",
       "       [    0.42292,     0.50156],\n",
       "       [    0.42292,     0.49531],\n",
       "       [    0.42083,     0.49375],\n",
       "       [    0.42083,     0.48438],\n",
       "       [    0.41875,     0.48281],\n",
       "       [    0.41875,       0.475],\n",
       "       [    0.41667,     0.47344],\n",
       "       [    0.41667,     0.46875],\n",
       "       [    0.41458,     0.46719],\n",
       "       [    0.41458,     0.46406],\n",
       "       [     0.4125,      0.4625],\n",
       "       [     0.4125,     0.45937],\n",
       "       [    0.41042,     0.45781],\n",
       "       [    0.41042,     0.45625],\n",
       "       [    0.40833,     0.45469],\n",
       "       [    0.40833,     0.45312],\n",
       "       [    0.39583,     0.44375],\n",
       "       [    0.39375,     0.44375],\n",
       "       [    0.38958,     0.44063],\n",
       "       [     0.3875,     0.44063],\n",
       "       [    0.38333,      0.4375],\n",
       "       [    0.38333,     0.43594],\n",
       "       [    0.38125,     0.43437],\n",
       "       [    0.38125,     0.43125],\n",
       "       [    0.37917,     0.42969],\n",
       "       [    0.37917,       0.425],\n",
       "       [    0.38125,     0.42344],\n",
       "       [    0.38125,     0.40156],\n",
       "       [    0.37917,         0.4],\n",
       "       [    0.37917,     0.39375],\n",
       "       [    0.37708,     0.39219],\n",
       "       [    0.37708,     0.38906],\n",
       "       [      0.375,      0.3875],\n",
       "       [      0.375,     0.38438],\n",
       "       [    0.37292,     0.38281],\n",
       "       [    0.37292,     0.38125],\n",
       "       [    0.36875,     0.37813],\n",
       "       [    0.36875,     0.37187]], dtype=float32), array([[  0.0041667,     0.23438],\n",
       "       [  0.0041667,     0.30781],\n",
       "       [     0.0125,     0.30781],\n",
       "       [     0.0125,     0.30156],\n",
       "       [   0.014583,         0.3],\n",
       "       [   0.016667,         0.3],\n",
       "       [   0.020833,     0.29688],\n",
       "       [   0.022917,     0.29688],\n",
       "       [   0.022917,     0.29531],\n",
       "       [   0.029167,     0.29063],\n",
       "       [   0.029167,     0.28906],\n",
       "       [     0.0375,     0.28281],\n",
       "       [    0.04375,     0.28281],\n",
       "       [    0.04375,     0.25469],\n",
       "       [     0.0375,     0.25469],\n",
       "       [    0.03125,        0.25],\n",
       "       [    0.03125,     0.24844],\n",
       "       [   0.029167,     0.24688],\n",
       "       [   0.029167,     0.24531],\n",
       "       [   0.027083,     0.24375],\n",
       "       [   0.027083,     0.24219],\n",
       "       [      0.025,     0.24062],\n",
       "       [      0.025,     0.23438]], dtype=float32), array([[          0,     0.51562],\n",
       "       [          0,     0.80313],\n",
       "       [  0.0083333,     0.80313],\n",
       "       [   0.010417,     0.80469],\n",
       "       [     0.0125,     0.80313],\n",
       "       [   0.027083,     0.80313],\n",
       "       [    0.03125,         0.8],\n",
       "       [   0.033333,         0.8],\n",
       "       [   0.035417,     0.79844],\n",
       "       [   0.035417,     0.79375],\n",
       "       [   0.033333,     0.79219],\n",
       "       [   0.033333,     0.79062],\n",
       "       [    0.03125,     0.78906],\n",
       "       [    0.03125,      0.7875],\n",
       "       [   0.029167,     0.78594],\n",
       "       [   0.029167,     0.78438],\n",
       "       [   0.027083,     0.78281],\n",
       "       [   0.027083,     0.77969],\n",
       "       [      0.025,     0.77812],\n",
       "       [      0.025,     0.74844],\n",
       "       [   0.027083,     0.74687],\n",
       "       [   0.027083,     0.74063],\n",
       "       [   0.029167,     0.73906],\n",
       "       [   0.029167,     0.70156],\n",
       "       [    0.03125,         0.7],\n",
       "       [    0.03125,     0.69844],\n",
       "       [   0.033333,     0.69687],\n",
       "       [   0.035417,     0.69687],\n",
       "       [     0.0375,     0.69531],\n",
       "       [   0.045833,     0.69531],\n",
       "       [   0.047917,     0.69687],\n",
       "       [   0.052083,     0.69687],\n",
       "       [    0.05625,         0.7],\n",
       "       [    0.05625,     0.70938],\n",
       "       [   0.058333,     0.71094],\n",
       "       [   0.058333,     0.71719],\n",
       "       [   0.060417,     0.71875],\n",
       "       [   0.060417,     0.72188],\n",
       "       [     0.0625,     0.72344],\n",
       "       [     0.0625,     0.72812],\n",
       "       [   0.064583,     0.72812],\n",
       "       [    0.06875,     0.73125],\n",
       "       [   0.070833,     0.73125],\n",
       "       [   0.077083,     0.72656],\n",
       "       [   0.085417,     0.73281],\n",
       "       [   0.085417,     0.73125],\n",
       "       [     0.0875,     0.72969],\n",
       "       [     0.0875,     0.70781],\n",
       "       [   0.085417,     0.70625],\n",
       "       [   0.085417,     0.70156],\n",
       "       [   0.083333,         0.7],\n",
       "       [   0.083333,     0.69531],\n",
       "       [    0.08125,     0.69375],\n",
       "       [    0.08125,     0.68594],\n",
       "       [   0.079167,     0.68437],\n",
       "       [   0.079167,     0.67656],\n",
       "       [   0.077083,       0.675],\n",
       "       [   0.077083,     0.66875],\n",
       "       [      0.075,     0.66719],\n",
       "       [      0.075,      0.6625],\n",
       "       [   0.072917,     0.66094],\n",
       "       [   0.072917,     0.65938],\n",
       "       [   0.070833,     0.65781],\n",
       "       [   0.070833,     0.65469],\n",
       "       [    0.06875,     0.65312],\n",
       "       [    0.06875,        0.65],\n",
       "       [   0.066667,     0.64844],\n",
       "       [   0.066667,     0.64531],\n",
       "       [   0.064583,     0.64375],\n",
       "       [   0.064583,     0.64219],\n",
       "       [   0.060417,     0.63906],\n",
       "       [   0.060417,     0.63594],\n",
       "       [   0.058333,     0.63437],\n",
       "       [   0.058333,     0.63281],\n",
       "       [    0.05625,     0.63125],\n",
       "       [    0.05625,     0.62813],\n",
       "       [   0.054167,     0.62656],\n",
       "       [   0.054167,     0.62344],\n",
       "       [   0.052083,     0.62187],\n",
       "       [   0.052083,     0.62031],\n",
       "       [       0.05,     0.61875],\n",
       "       [       0.05,     0.61719],\n",
       "       [   0.047917,     0.61563],\n",
       "       [   0.047917,     0.61406],\n",
       "       [   0.045833,      0.6125],\n",
       "       [   0.045833,     0.61094],\n",
       "       [    0.04375,     0.60938],\n",
       "       [    0.04375,     0.60625],\n",
       "       [   0.041667,     0.60469],\n",
       "       [   0.041667,     0.60312],\n",
       "       [   0.039583,     0.60156],\n",
       "       [   0.039583,     0.59844],\n",
       "       [     0.0375,     0.59688],\n",
       "       [     0.0375,     0.59375],\n",
       "       [   0.035417,     0.59219],\n",
       "       [   0.035417,     0.59062],\n",
       "       [   0.033333,     0.58906],\n",
       "       [   0.033333,      0.5875],\n",
       "       [    0.03125,     0.58594],\n",
       "       [    0.03125,     0.58438],\n",
       "       [   0.029167,     0.58281],\n",
       "       [   0.029167,     0.57969],\n",
       "       [   0.027083,     0.57812],\n",
       "       [   0.027083,       0.575],\n",
       "       [      0.025,     0.57344],\n",
       "       [      0.025,     0.56406],\n",
       "       [   0.022917,      0.5625],\n",
       "       [   0.022917,     0.55625],\n",
       "       [   0.020833,     0.55469],\n",
       "       [   0.020833,        0.55],\n",
       "       [    0.01875,     0.54844],\n",
       "       [    0.01875,     0.54531],\n",
       "       [   0.016667,     0.54375],\n",
       "       [   0.016667,     0.54062],\n",
       "       [   0.014583,     0.53906],\n",
       "       [   0.014583,     0.52969],\n",
       "       [     0.0125,     0.52812],\n",
       "       [     0.0125,     0.51562]], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = result.masks\n",
    "print(len(masks.data))\n",
    "masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d364464",
   "metadata": {},
   "source": [
    "# Fast Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce48fa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastSAM(\n",
       "  (model): SegmentationModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Segment(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (proto): Proto(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (upsample): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv4): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fs = FastSAM('FastSAM-s.pt')\n",
    "model_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12081663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\walker\\code\\deep-learning-models\\models\\sam\\..\\..\\data\\image\\dog.jpeg: 640x384 12 objects, 161.8ms\n",
      "Speed: 2.4ms preprocess, 161.8ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\walker\\code\\deep-learning-models\\runs\\segment\\predict5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# conf 값으로 최소 정확도값 지정\n",
    "results_fs = model_fs('../../data/image/dog.jpeg', save=True, conf=0.7)\n",
    "result_fs = results_fs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86cf0124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masks_fs = result_fs.masks\n",
    "\n",
    "plt.imshow(masks_fs.data[7])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14580329",
   "metadata": {},
   "source": [
    "# 3. 이미지와 프롬프트로 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b671ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\walker\\code\\deep-learning-models\\models\\sam\\..\\..\\data\\image\\dog.jpeg: 640x384 1 object, 168.1ms\n",
      "Speed: 4.1ms preprocess, 168.1ms inference, 7883.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\walker\\code\\deep-learning-models\\runs\\segment\\predict5\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: ultralytics.engine.results.Masks object\n",
       " names: {0: 'object'}\n",
       " obb: None\n",
       " orig_img: array([[[202, 157, 120],\n",
       "         [202, 157, 120],\n",
       "         [202, 157, 120],\n",
       "         ...,\n",
       "         [199, 161, 129],\n",
       "         [198, 160, 128],\n",
       "         [198, 160, 128]],\n",
       " \n",
       "        [[201, 156, 119],\n",
       "         [201, 156, 119],\n",
       "         [201, 156, 119],\n",
       "         ...,\n",
       "         [199, 161, 129],\n",
       "         [199, 161, 129],\n",
       "         [198, 160, 128]],\n",
       " \n",
       "        [[201, 156, 119],\n",
       "         [201, 156, 119],\n",
       "         [201, 156, 119],\n",
       "         ...,\n",
       "         [200, 162, 130],\n",
       "         [199, 161, 129],\n",
       "         [199, 161, 129]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[202, 204, 205],\n",
       "         [220, 222, 223],\n",
       "         [233, 235, 236],\n",
       "         ...,\n",
       "         [109, 124, 150],\n",
       "         [112, 126, 154],\n",
       "         [106, 123, 150]],\n",
       " \n",
       "        [[197, 199, 200],\n",
       "         [225, 227, 228],\n",
       "         [220, 222, 223],\n",
       "         ...,\n",
       "         [106, 121, 147],\n",
       "         [105, 119, 147],\n",
       "         [105, 121, 150]],\n",
       " \n",
       "        [[208, 210, 211],\n",
       "         [194, 196, 197],\n",
       "         [221, 223, 224],\n",
       "         ...,\n",
       "         [103, 118, 144],\n",
       "         [106, 120, 148],\n",
       "         [118, 134, 163]]], shape=(1280, 720, 3), dtype=uint8)\n",
       " orig_shape: (1280, 720)\n",
       " path: 'c:\\\\walker\\\\code\\\\deep-learning-models\\\\models\\\\sam\\\\..\\\\..\\\\data\\\\image\\\\dog.jpeg'\n",
       " probs: None\n",
       " save_dir: 'C:\\\\walker\\\\code\\\\deep-learning-models\\\\runs\\\\segment\\\\predict5'\n",
       " speed: {'preprocess': 4.070499911904335, 'inference': 168.14709990285337, 'postprocess': 7883.209299994633}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fs('../../data/image/dog.jpeg', save=True, texts='a photo of dog')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
